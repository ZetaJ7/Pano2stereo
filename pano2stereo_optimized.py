import torch
import numpy as np
import threading
import time
import math
import os
import cv2
import logging
import subprocess
from pathlib import Path
from tqdm import tqdm
from depth_estimate import depth_estimation
from submodule.DepthAnythingv2.metric_depth.depth_anything_v2.dpt import DepthAnythingV2
from numba import cuda
import cupy as cp
from contextlib import contextmanager
import gc

# å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
try:
    import config
    PARAMS = {
        "IPD": config.IPD,
        "PRO_RADIUS": config.PRO_RADIUS,
        "PIXEL": config.PIXEL,
        "CRITICAL_DEPTH": config.CRITICAL_DEPTH,
        "GENERATE_VIDEO": config.GENERATE_VIDEO,
        "IMG_PATH": config.IMG_PATH,
        "VIT_SIZE": config.VIT_SIZE,
        "DATASET": config.DATASET,
        "OUTPUT_BASE": config.OUTPUT_BASE,
        "ENABLE_REPAIR": config.ENABLE_REPAIR,
        "ENABLE_POST_PROCESS": config.ENABLE_POST_PROCESS,
        "ENABLE_RED_CYAN": config.ENABLE_RED_CYAN,
        "TARGET_HEIGHT": config.TARGET_HEIGHT,
        "TARGET_WIDTH": config.TARGET_WIDTH
    }
    logging.info("Configuration loaded from config.py")
except ImportError:
    logging.warning("config.py not found, using default parameters")
    # é»˜è®¤å‚æ•°ï¼ˆå¦‚æœæ²¡æœ‰é…ç½®æ–‡ä»¶ï¼‰
    PARAMS = {
        "IPD": 0.032,                      # è§†ç¯åŠå¾„(m)
        "PRO_RADIUS": 1,                   # è§†ç¯æŠ•å½±åŠå¾„(m)
        "PIXEL": 4448,                     # èµ¤é“å›¾åƒå®½åº¦(pixel)
        "CRITICAL_DEPTH": 9999,            # ä¸´ç•Œæ·±åº¦(m)
        "GENERATE_VIDEO": 0,               # æ˜¯å¦ç”Ÿæˆè§†é¢‘
        "IMG_PATH": "Data/Lab1_2k.png",       # è¾“å…¥å›¾ç‰‡è·¯å¾„
        "VIT_SIZE": "vits",                # æ·±åº¦æ¨¡å‹ç±»å‹
        "DATASET": "hypersim",             # æ·±åº¦æ¨¡å‹æ•°æ®é›†
        "OUTPUT_BASE": "results/output",   # è¾“å‡ºç›®å½•åŸºç¡€å
        "ENABLE_REPAIR": True,             # æ˜¯å¦å¯ç”¨å›¾åƒä¿®å¤
        "ENABLE_POST_PROCESS": True,       # æ˜¯å¦å¯ç”¨åå¤„ç†
        "ENABLE_RED_CYAN": False,          # æ˜¯å¦ç”Ÿæˆçº¢é’3Då›¾ï¼ˆé»˜è®¤å…³é—­ä»¥æå‡é€Ÿåº¦ï¼‰
        "TARGET_HEIGHT": 540,              # ç›®æ ‡é«˜åº¦ï¼ˆé™ä½åˆ†è¾¨ç‡æå‡é€Ÿåº¦ï¼‰
        "TARGET_WIDTH": 960                # ç›®æ ‡å®½åº¦
    }

# ================== æ€§èƒ½ç›‘æ§ ==================
class PerformanceProfiler:
    def __init__(self):
        self.timings = {}
        self.active_timers = {}
    
    def reset(self):
        """é‡ç½®è®¡æ—¶å™¨æ•°æ®"""
        self.timings.clear()
        self.active_timers.clear()
    
    def get_timing(self, name):
        """è·å–æŒ‡å®šè®¡æ—¶å™¨çš„æœ€æ–°æ—¶é—´"""
        if name in self.timings and self.timings[name]:
            return self.timings[name][-1]  # è¿”å›æœ€æ–°çš„æ—¶é—´
        return None
    
    @contextmanager
    def timer(self, name):
        start_time = time.perf_counter()
        try:
            yield
        finally:
            end_time = time.perf_counter()
            elapsed = end_time - start_time
            if name not in self.timings:
                self.timings[name] = []
            self.timings[name].append(elapsed)
            
            # ç«‹å³è¾“å‡ºå¹¶åˆ·æ–°æ—¥å¿—
            message = f"[TIMER] {name}: {elapsed:.4f}s"
            logging.info(message)
            # å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰handlers
            for handler in logging.getLogger().handlers:
                handler.flush()
    
    def get_summary(self):
        summary = "\n" + "="*50 + "\n[TIMER] Performance Summary:\n" + "="*50
        total_time = 0
        for name, times in self.timings.items():
            avg_time = sum(times) / len(times)
            max_time = max(times)
            min_time = min(times)
            total_time += sum(times)
            summary += f"\n{name}:"
            summary += f"\n  Average: {avg_time:.4f}s"
            summary += f"\n  Min: {min_time:.4f}s"
            summary += f"\n  Max: {max_time:.4f}s"
            summary += f"\n  Total: {sum(times):.4f}s"
            summary += f"\n  Count: {len(times)}"
        summary += f"\n{'-'*50}"
        summary += f"\nTotal execution time: {total_time:.4f}s"
        summary += f"\n{'='*50}"
        return summary

# å…¨å±€æ€§èƒ½åˆ†æå™¨
profiler = PerformanceProfiler()

model_configs = {
    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},
    'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},
    'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},
}

def logging_setup():
    # è®¾ç½®OpenCVæ—¥å¿—çº§åˆ«ï¼Œå‡å°‘è­¦å‘Š
    try:
        cv2.setLogLevel(3)  # 3=ERRORçº§åˆ«ï¼Œå‡å°‘è­¦å‘Šä¿¡æ¯
    except:
        pass  # å¦‚æœè®¾ç½®å¤±è´¥å°±è·³è¿‡
    
    # ç¡®ä¿logsç›®å½•å­˜åœ¨
    os.makedirs('logs', exist_ok=True)
    
    # é…ç½®æ—¥å¿— - å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒº
    file_handler = logging.FileHandler('logs/pano2stereo.log', mode='w', encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    # è·å–æ ¹loggerå¹¶é…ç½®
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    root_logger.handlers.clear()  # æ¸…é™¤ç°æœ‰handlers
    root_logger.addHandler(file_handler)
    root_logger.addHandler(console_handler)
    
    # å¼ºåˆ¶åˆ·æ–°
    logging.info("=== Pano2Stereo Optimized Processing Started ===")
    for handler in root_logger.handlers:
        handler.flush()

def cal_critical_depth(r, pixel):
    return r / (math.sin(2 * math.pi / pixel))

class OptimizedStereoPano():
    def __init__(self, height, width, IPD, pro_radius, pixel, critical_depth, vit_size='vits', dataset='hypersim'):
        logging.info('Initializing Optimized StereoPano Generator')
        self.IPD = IPD
        self.width = width
        self.height = height
        self.pro_radius = pro_radius
        self.pixel = pixel
        self.critical_depth = critical_depth
        self.device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'
        
        # ç«‹å³åŠ è½½æ¨¡å‹ï¼ˆè€Œä¸æ˜¯å»¶è¿ŸåŠ è½½ï¼‰
        logging.info("Loading depth estimation model...")
        self.model = DepthAnythingV2(**{**model_configs[vit_size], 'max_depth': 20})
        self.model.load_state_dict(torch.load(f'checkpoints/depth_anything_v2_metric_{dataset}_{vit_size}.pth', map_location=self.device))
        self.model = self.model.to(self.device).eval()
        logging.info(f'[DepthAnythingV2] Model loaded: {vit_size}-{dataset}')
        
        # ä¼˜åŒ–ï¼šé¢„è®¡ç®—æ‰€æœ‰éœ€è¦çš„åæ ‡å˜æ¢
        logging.info("Precomputing sphere coordinates...")
        self.sphere_coords = self._precompute_sphere_coords(width, height)
        # é¢„è®¡ç®—ç½‘æ ¼åæ ‡ç”¨äºå¿«é€Ÿé‡‡æ ·
        self.grid_y, self.grid_x = cp.meshgrid(cp.arange(height), cp.arange(width), indexing='ij')
        
        # æ¨¡å‹é¢„çƒ­ï¼ˆåœ¨åˆå§‹åŒ–æ—¶å®Œæˆï¼‰
        logging.info("Warming up model for optimal performance...")
        # ä½¿ç”¨å®é™…è¾“å…¥å°ºå¯¸è¿›è¡Œé¢„çƒ­
        dummy_input = np.random.rand(height, width, 3).astype(np.float32)
        dummy_input = (dummy_input * 255).astype(np.uint8)  # æ¨¡æ‹ŸçœŸå®å›¾åƒæ ¼å¼
        _ = self.model.infer_image(dummy_input)
        # æ¸…ç†é¢„çƒ­æ—¶çš„å†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        logging.info("Model warmup completed")
        
        logging.info('[OptimizedStereoPano] Initialization completed')

    def _precompute_sphere_coords(self, image_width, image_height):
        """ä¼˜åŒ–çš„çƒé¢åæ ‡é¢„è®¡ç®—"""
        # ä½¿ç”¨æ›´é«˜æ•ˆçš„åæ ‡ç”Ÿæˆ
        x = cp.linspace(0, image_width - 1, image_width, dtype=cp.float32)
        y = cp.linspace(0, image_height - 1, image_height, dtype=cp.float32)
        xx, yy = cp.meshgrid(x, y)
        
        # å‘é‡åŒ–è®¡ç®—
        u = (xx / (image_width - 1)) * 2 - 1
        v = (yy / (image_height - 1)) * -2 + 1
        lon = u * cp.pi
        lat = v * (cp.pi / 2)
        
        # çƒé¢åæ ‡è®¡ç®—
        x_xyz = cp.cos(lat) * cp.cos(lon)
        y_xyz = cp.cos(lat) * cp.sin(lon)
        z_xyz = cp.sin(lat)
        
        # ä½¿ç”¨æ›´ç¨³å®šçš„è®¡ç®—æ–¹å¼
        r = cp.ones_like(x_xyz)  # å•ä½çƒé¢ï¼Œr=1
        theta = cp.arccos(cp.clip(z_xyz, -1, 1))
        phi = cp.arctan2(y_xyz, x_xyz)
        
        return cp.stack([r, theta, phi], axis=-1)

    def sphere_to_image_coords(self, sphere_coords, image_width, image_height):
        """åŸç‰ˆæœ¬çš„çƒé¢åˆ°å›¾åƒåæ ‡è½¬æ¢ï¼ˆæ›´é«˜æ•ˆï¼‰"""
        with profiler.timer("Sphere_to_image_coords"):
            sphere_coords = cp.asarray(sphere_coords)
            r = sphere_coords[..., 0]
            theta = sphere_coords[..., 1]
            phi = sphere_coords[..., 2]
            theta = cp.clip(theta, 0, cp.pi)
            phi = (phi + cp.pi) % (2 * cp.pi) - cp.pi
            lat = cp.pi / 2 - theta
            lon = phi
            u = lon / cp.pi
            v = lat / (cp.pi / 2)
            x_float = (u + 1) * 0.5 * (image_width - 1)
            y_float = (1 - v) * 0.5 * (image_height - 1)
            x = cp.round(x_float).astype(cp.int32)
            y = cp.round(y_float).astype(cp.int32)
            image_coords = cp.stack([
                cp.clip(x, 0, image_width - 1),
                cp.clip(y, 0, image_height - 1)
            ], axis=-1)
            return image_coords

    def sphere2pano_vectorized(self, sphere_coords, z_vals):
        """åŸç‰ˆæœ¬çš„é«˜æ•ˆçƒé¢è§†å·®è®¡ç®—"""
        with profiler.timer("Sphere2pano_vectorized"):
            R = cp.asarray(sphere_coords[..., 0])
            theta = cp.asarray(sphere_coords[..., 1])
            phi = cp.asarray(sphere_coords[..., 2])
            mask = z_vals < self.critical_depth
            ratio = cp.clip(self.IPD / cp.where(mask, z_vals, cp.inf), -1.0, 1.0)
            delta = cp.arcsin(ratio)
            phi_l = (phi + delta) % (2 * cp.pi)
            phi_r = (phi - delta) % (2 * cp.pi)
            return (
                cp.stack([R, theta, phi_l], axis=-1),
                cp.stack([R, theta, phi_r], axis=-1)
            )

    def generate_stereo_pair_vectorized(self, rgb_data, depth_data):
        """åŸç‰ˆæœ¬çš„é«˜æ•ˆç«‹ä½“å¯¹ç”Ÿæˆ"""
        with profiler.timer("Generate_stereo_pair_total"):
            logging.info("=============== Generating stereo pair (Original Method) ================")
            
            with profiler.timer("Sphere2pano_calculation"):
                sphere_l, sphere_r = self.sphere2pano_vectorized(self.sphere_coords, depth_data)
            
            with profiler.timer("Coordinate_mapping"):
                coords_l = self.sphere_to_image_coords(sphere_l, self.width, self.height)
                coords_r = self.sphere_to_image_coords(sphere_r, self.width, self.height)
            
            with profiler.timer("Image_sampling"):
                xl, yl = coords_l[..., 0], coords_l[..., 1]
                xr, yr = coords_r[..., 0], coords_r[..., 1]
                left = cp.zeros_like(rgb_data)
                right = cp.zeros_like(rgb_data)
                left[cp.arange(self.height)[:, None], cp.arange(self.width), :] = rgb_data[yl, xl, :]
                right[cp.arange(self.height)[:, None], cp.arange(self.width), :] = rgb_data[yr, xr, :]
            
            return left, right

    def generate_stereo_pair(self, rgb_array, depth):
        """ç»Ÿä¸€çš„ç«‹ä½“å¯¹ç”Ÿæˆå…¥å£"""
        return self.generate_stereo_pair_vectorized(rgb_array, depth)

    def repair_black_regions_fast(self, image):
        """å¿«é€Ÿé»‘è‰²åŒºåŸŸä¿®å¤ï¼ˆå¯é€‰ï¼‰"""
        if not PARAMS["ENABLE_REPAIR"]:
            return cp.asnumpy(image)
            
        # è½¬æ¢åˆ°CPUè¿›è¡Œä¿®å¤
        image_cpu = cp.asnumpy(image).astype(np.uint8)
        
        # å¿«é€Ÿæ£€æµ‹æ˜¯å¦éœ€è¦ä¿®å¤
        gray = cv2.cvtColor(image_cpu, cv2.COLOR_RGB2GRAY)
        black_pixels = np.sum(gray == 0)
        
        if black_pixels < gray.size * 0.01:  # å¦‚æœé»‘è‰²åƒç´ å°‘äº1%ï¼Œè·³è¿‡ä¿®å¤
            return image_cpu
        
        # ä½¿ç”¨æ›´å¿«çš„ä¿®å¤ç®—æ³•
        img_bgr = cv2.cvtColor(image_cpu, cv2.COLOR_RGB2BGR)
        mask = np.uint8(gray == 0) * 255
        repaired = cv2.inpaint(img_bgr, mask, inpaintRadius=2, flags=cv2.INPAINT_NS)  # ä½¿ç”¨æ›´å¿«çš„ç®—æ³•
        return cv2.cvtColor(repaired, cv2.COLOR_BGR2RGB)

    def make_output_dir(self, base_dir=None):
        if base_dir is None:
            base_dir = PARAMS["OUTPUT_BASE"]
        index = 0
        while True:
            target_dir = f"{base_dir}_{index:03d}" if index >= 0 else base_dir
            if not os.path.exists(target_dir):
                os.makedirs(target_dir)
                break
            index += 1
        return target_dir

# =============== ä¼˜åŒ–çš„åŠŸèƒ½å‡½æ•° ===============

def load_and_resize_image(img_path):
    """åŠ è½½å¹¶å¯é€‰åœ°è°ƒæ•´å›¾åƒå¤§å°ä»¥æå‡é€Ÿåº¦"""
    if not os.path.exists(img_path):
        raise FileNotFoundError(f"File Not Found: {img_path}")
    
    bgr_array = cv2.imread(img_path, cv2.IMREAD_COLOR)
    if bgr_array is None:
        raise FileNotFoundError(f"Cannot Read file: {img_path}")
    
    rgb_array = cv2.cvtColor(bgr_array, cv2.COLOR_BGR2RGB)
    
    # å¯é€‰ï¼šè°ƒæ•´å›¾åƒå¤§å°ä»¥æå‡å¤„ç†é€Ÿåº¦
    original_height, original_width = rgb_array.shape[:2]
    if (PARAMS.get("TARGET_HEIGHT") and PARAMS.get("TARGET_WIDTH") and 
        (original_height > PARAMS["TARGET_HEIGHT"] or original_width > PARAMS["TARGET_WIDTH"])):
        
        rgb_array = cv2.resize(rgb_array, (PARAMS["TARGET_WIDTH"], PARAMS["TARGET_HEIGHT"]))
        logging.info(f"Image resized from {original_width}x{original_height} to {PARAMS['TARGET_WIDTH']}x{PARAMS['TARGET_HEIGHT']}")
    
    logging.info(f"Input Image: {img_path}")
    logging.info(f"Image Size: {rgb_array.shape[1]}x{rgb_array.shape[0]}")
    return rgb_array

def estimate_depth_optimized(generator, rgb_array):
    """ä¼˜åŒ–çš„æ·±åº¦ä¼°è®¡ï¼ˆæ¨¡å‹å·²é¢„çƒ­ï¼‰"""
    with profiler.timer("ğŸ§  Depth_estimation"):
        depth = generator.model.infer_image(rgb_array)
        return cp.asarray(depth, dtype=cp.float32)

def save_results_optimized(left, right, left_repaired, right_repaired, depth, output_dir):
    """ä¼˜åŒ–çš„ç»“æœä¿å­˜"""
    # å¹¶è¡Œä¿å­˜å¤šä¸ªå›¾åƒ
    def save_image(img, path, is_gpu=True):
        if is_gpu and hasattr(img, 'get'):
            img = img.get()
        elif is_gpu:
            img = cp.asnumpy(img)
        
        if len(img.shape) == 3 and img.shape[2] == 3:  # RGBå›¾åƒ
            img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
            cv2.imwrite(str(path), img_bgr)
        else:
            cv2.imwrite(str(path), img)
    
    output_path = Path(output_dir)
    
    # ä¿å­˜ä¸»è¦å›¾åƒ
    save_image(left, output_path / "left.png")
    save_image(right, output_path / "right.png")
    save_image(left_repaired, output_path / "left_repaired.png", is_gpu=False)
    save_image(right_repaired, output_path / "right_repaired.png", is_gpu=False)
    
    # ä¿®å¤æ·±åº¦å›¾ä¿å­˜ï¼Œæ¶ˆé™¤è­¦å‘Š
    try:
        # æ­£ç¡®è·å–æ·±åº¦æ•°æ®
        if hasattr(depth, 'get'):
            depth_cpu = depth.get()
        elif isinstance(depth, cp.ndarray):
            depth_cpu = cp.asnumpy(depth)
        else:
            depth_cpu = depth
        
        # ç¡®ä¿ä¸ºnumpyæ•°ç»„
        if not isinstance(depth_cpu, np.ndarray):
            depth_cpu = np.array(depth_cpu)
        
        # æ­£ç¡®å¤„ç†æ·±åº¦å›¾æ•°æ®ç±»å‹å’ŒèŒƒå›´
        if depth_cpu.dtype != np.uint8:
            # è·å–æœ‰æ•ˆæ·±åº¦å€¼ï¼ˆæ’é™¤infå’Œnanï¼‰
            valid_mask = np.isfinite(depth_cpu)
            if np.any(valid_mask):
                depth_min = np.min(depth_cpu[valid_mask])
                depth_max = np.max(depth_cpu[valid_mask])
                
                # å½’ä¸€åŒ–åˆ°0-255èŒƒå›´
                if depth_max > depth_min:
                    depth_normalized = np.zeros_like(depth_cpu, dtype=np.uint8)
                    depth_normalized[valid_mask] = ((depth_cpu[valid_mask] - depth_min) / 
                                                   (depth_max - depth_min) * 255).astype(np.uint8)
                else:
                    depth_normalized = np.zeros_like(depth_cpu, dtype=np.uint8)
            else:
                depth_normalized = np.zeros_like(depth_cpu, dtype=np.uint8)
        else:
            depth_normalized = depth_cpu.astype(np.uint8)
        
        # ä¿å­˜æ·±åº¦å›¾ï¼ˆç°åœ¨æ˜¯æ­£ç¡®çš„uint8æ ¼å¼ï¼‰
        cv2.imwrite(str(output_path / 'depth.png'), depth_normalized)
        
        if 'valid_mask' in locals() and np.any(valid_mask):
            logging.info(f"Depth map saved (range: {depth_min:.3f}-{depth_max:.3f}m â†’ 0-255)")
        else:
            logging.info("Depth map saved (uint8 format)")
            
    except Exception as e:
        logging.warning(f"Depth map save failed: {e}")

def post_process_optimized(output_dir, width, height):
    """ä¼˜åŒ–çš„åå¤„ç†ï¼ˆå¯é€‰çº¢é’3DåŠŸèƒ½ï¼‰"""
    if not PARAMS["ENABLE_POST_PROCESS"]:
        logging.info("Post-processing disabled for speed")
        return
        
    output_dir = Path(output_dir).absolute()
    try:
        # å¯é€‰ï¼šç”Ÿæˆçº¢é’3Då›¾
        if PARAMS["ENABLE_RED_CYAN"]:
            subprocess.run([
                "StereoscoPy",
                "-S", "5", "0",
                "-a",
                "-m", "color",
                "--cs", "red-cyan",
                "--lc", "rgb",
                str(output_dir / "left_repaired.png"),
                str(output_dir / "right_repaired.png"),
                str(output_dir / "red_cyan.jpg")
            ], check=True, capture_output=True)
            logging.info("Red-cyan 3D image generated")
        else:
            logging.info("Red-cyan 3D generation skipped (disabled for speed)")

        # ç”Ÿæˆå·¦å³æ‹¼æ¥ç«‹ä½“å›¾
        subprocess.run([
            "ffmpeg", "-y", "-loglevel", "error",  # å‡å°‘æ—¥å¿—è¾“å‡º
            "-i", str(output_dir / "left_repaired.png"),
            "-i", str(output_dir / "right_repaired.png"),
            "-filter_complex", f"[0:v][1:v]hstack", 
            "-frames:v", "1", 
            str(output_dir / "stereo.jpg")
        ], check=True, capture_output=True)

        # å¯é€‰ï¼šç”Ÿæˆè§†é¢‘
        if PARAMS["GENERATE_VIDEO"]:
            logging.info("Generating video...")
            subprocess.run([
                "ffmpeg", "-y", "-loglevel", "error",
                "-loop", "1",
                "-i", str(output_dir / "stereo.jpg"),
                "-c:v", "libx264",
                "-t", "60",
                "-pix_fmt", "yuv420p",
                "-vf", "fps=30",
                str(output_dir / "stereo_output.mp4")
            ], check=True, capture_output=True)

    except subprocess.CalledProcessError as e:
        logging.error(f"Post-process failure: {e.returncode}")
    except Exception as e:
        logging.error(f"Post-process error: {str(e)}")
    else:
        red_cyan_status = "with red-cyan 3D" if PARAMS["ENABLE_RED_CYAN"] else "without red-cyan 3D"
        logging.info(f"Post-processing completed ({red_cyan_status})")
    
    logging.info(f"Output Dir: {output_dir}")

# =============== ä¸»æµç¨‹ä¼˜åŒ–ç‰ˆ ===============
def main_optimized():
    """ä¼˜åŒ–çš„ä¸»å‡½æ•°ï¼ˆä¸“æ³¨æ ¸å¿ƒè®¡æ—¶ï¼‰"""
    profiler.reset()
    
    # é…ç½®å‚æ•°ï¼ˆä¸å‚ä¸æ ¸å¿ƒè®¡æ—¶ï¼‰
    img_path = PARAMS["IMG_PATH"]
    IPD = PARAMS["IPD"]
    PRO_RADIUS = PARAMS["PRO_RADIUS"]
    PIXEL = PARAMS["PIXEL"]
    CRITICAL_DEPTH = min(PARAMS["CRITICAL_DEPTH"], cal_critical_depth(IPD, PIXEL))
    
    logging.info(f"\n{'='*60}")
    logging.info(f"ğŸ¯ Core Processing Performance Analysis")
    logging.info(f"{'='*60}")
    
    try:
        # 1. ğŸ“¸ å›¾åƒåŠ è½½ï¼ˆæ ¸å¿ƒè®¡æ—¶å¼€å§‹ï¼‰
        with profiler.timer("ğŸ“¸ Image_loading"):
            rgb_array = load_and_resize_image(img_path)
            height, width = rgb_array.shape[:2]
            logging.info(f"Image loaded: {width}x{height}")

        # 2. ç”Ÿæˆå™¨åˆå§‹åŒ–ï¼ˆå«æ¨¡å‹é¢„çƒ­ï¼Œä¸å‚ä¸æ ¸å¿ƒè®¡æ—¶ï¼‰
        logging.info(f'[Optimized Stereo] IPD: {IPD}m, Critical Depth: {CRITICAL_DEPTH:.2f}m')
        # å¼ºåˆ¶åˆ·æ–°æ—¥å¿—
        for handler in logging.getLogger().handlers:
            handler.flush()
            
        generator = OptimizedStereoPano(
            height=height, width=width, IPD=IPD, pro_radius=PRO_RADIUS, 
            pixel=PIXEL, critical_depth=CRITICAL_DEPTH, 
            vit_size=PARAMS["VIT_SIZE"], dataset=PARAMS["DATASET"]
        )
        
        # 3. ğŸ§  æ·±åº¦ä¼°è®¡ï¼ˆæ ¸å¿ƒè®¡æ—¶ï¼‰
        with profiler.timer("ğŸ§  Depth_estimation"):
            depth = generator.model.infer_image(rgb_array)
            depth_gpu = cp.asarray(depth, dtype=cp.float32)
            d_rgb = cp.asarray(rgb_array, dtype=cp.float32)
        
        # 4. ğŸ¯ ç«‹ä½“å¯¹ç”Ÿæˆï¼ˆæ ¸å¿ƒè®¡æ—¶ - ä½¿ç”¨åŸç‰ˆæœ¬æ–¹æ³•ï¼‰
        with profiler.timer("ğŸ¯ Stereo_pair_generation"):
            left, right = generator.generate_stereo_pair_vectorized(d_rgb, depth_gpu)
        
        # 5. ğŸ”§ å›¾åƒä¿®å¤ï¼ˆæ ¸å¿ƒè®¡æ—¶ - å¹¶è¡Œå¤„ç†ï¼‰
        with profiler.timer("ğŸ”§ Image_repair"):
            # å¹¶è¡Œä¿®å¤å·¦å³å›¾åƒ
            import concurrent.futures
            
            def repair_single_image(image):
                """å•ä¸ªå›¾åƒä¿®å¤å‡½æ•°"""
                if not PARAMS["ENABLE_REPAIR"]:
                    return cp.asnumpy(image)
                    
                # è½¬æ¢åˆ°CPUè¿›è¡Œä¿®å¤
                image_cpu = cp.asnumpy(image).astype(np.uint8)
                
                # å¿«é€Ÿæ£€æµ‹æ˜¯å¦éœ€è¦ä¿®å¤
                gray = cv2.cvtColor(image_cpu, cv2.COLOR_RGB2GRAY)
                black_pixels = np.sum(gray == 0)
                
                if black_pixels < gray.size * 0.01:  # å¦‚æœé»‘è‰²åƒç´ å°‘äº1%ï¼Œè·³è¿‡ä¿®å¤
                    return image_cpu
                
                # ä½¿ç”¨æ›´å¿«çš„ä¿®å¤ç®—æ³•
                img_bgr = cv2.cvtColor(image_cpu, cv2.COLOR_RGB2BGR)
                mask = np.uint8(gray == 0) * 255
                repaired = cv2.inpaint(img_bgr, mask, inpaintRadius=2, flags=cv2.INPAINT_NS)
                return cv2.cvtColor(repaired, cv2.COLOR_BGR2RGB)
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†å·¦å³å›¾åƒ
            with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
                # æäº¤å·¦å³å›¾åƒä¿®å¤ä»»åŠ¡
                future_left = executor.submit(repair_single_image, left)
                future_right = executor.submit(repair_single_image, right)
                
                # è·å–ç»“æœ
                left_repaired = future_left.result()
                right_repaired = future_right.result()

        # ä¿å­˜å’Œåå¤„ç†ï¼ˆä¸å‚ä¸æ ¸å¿ƒè®¡æ—¶ï¼‰
        output_dir = generator.make_output_dir()
        save_results_optimized(left, right, left_repaired, right_repaired, depth_gpu, output_dir)
        post_process_optimized(output_dir, width, height)
        
        # æ ¸å¿ƒå¤„ç†æ€§èƒ½æŠ¥å‘Š
        core_steps = ["ğŸ“¸ Image_loading", "ğŸ§  Depth_estimation", "ğŸ¯ Stereo_pair_generation", "ğŸ”§ Image_repair"]
        total_core_time = sum(profiler.get_timing(step) for step in core_steps if profiler.get_timing(step))
        
        logging.info(f"\nğŸ† Core Processing Summary:")
        for step in core_steps:
            time_val = profiler.get_timing(step)
            if time_val:
                logging.info(f"  {step}: {time_val:.3f}s")
        logging.info(f"  ğŸ’« Total Core Time: {total_core_time:.3f}s")
        
        # å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰æ—¥å¿—
        for handler in logging.getLogger().handlers:
            handler.flush()
        
        # å†…å­˜æ¸…ç†
        del d_rgb, depth_gpu, left, right
        cp.get_default_memory_pool().free_all_blocks()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            
        logging.info("=== Processing completed successfully ===")
        # æœ€ç»ˆåˆ·æ–°
        for handler in logging.getLogger().handlers:
            handler.flush()
            
    except Exception as e:
        logging.error(f"Processing failed: {str(e)}")
        raise

if __name__ == "__main__":
    logging_setup()
    main_optimized()
