# General settings
config_dir: null # overwrite by --config-path
inference: true
load: '/home/test/Lijunjie/Pano2stereo/models/flashdepth.pth'  # path to pth file or 'true' when checkpoint exists in config_dir

# Dataset configuration
dataset:
  data_root: null # change data path
  resolution: '2k'
  video_length: 5
  train_datasets: [mvs-synth,spring]  # Comma-separated list of dataset names
  val_datasets: [sintel,waymo]  # Comma-separated list of validation dataset names

# Model configuration
model:
  # ViT configuration
  vit_size: "vits"
  patch_size: 14
  attn_class: "MemEffAttention"

  # Mamba configuration
  use_mamba: true
  mamba_type: "add"
  num_mamba_layers: 4
  downsample_mamba: [0.1]
  mamba_pos_embed: null
  mamba_in_dpt_layer: [1]
  mamba_d_conv: 4
  mamba_d_state: 256
  use_hydra: false # https://github.com/goombalab/hydra
  use_transformer_rnn: false
  use_xlstm: false # https://github.com/NX-AI/xlstm

# hybrid model configuration
hybrid_configs:
  use_hybrid: true
  teacher_model_path: null
  teacher_resolution: 490
  layers_to_skip: [1,2,3] # only the 0th index (i.e. path 4 in dpt) is used for fusion
  num_blocks: 4
  mlp_expand: 2
  num_heads: 2


# Evaluation configuration
eval:
  # url: "rtsp://10.20.16.136:10054/test"
  url: "rtsp://10.20.35.30:28552/test"
  stream: true  # whether to use stream inference mode
  stream_max_frames: 100
  compile: false
  metrics: false
  save_grid: false
  outfolder: "result"
  test_datasets: [unreal4k,sintel,eth3d,waymo,urbansyn]
  test_dataset_resolution: '2k'
  random_input: null
  out_video: true # whether to save video at all
  out_mp4: false # mp4 if true, gif if false (default changed to false)
  save_res: 518
  save_depth_npy: false
  save_depth_png: true
  save_frame_png: true
  save_vis_map: false
  dummy_timing: false
  large_dir: null
  target_fps: 30  # Target FPS for stream processing to prevent overload
